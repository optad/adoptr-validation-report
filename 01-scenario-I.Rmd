# Scenario I: large effect, point prior {#scenarioI}


## Details

In this scenario, a classical two-arm trial with normal
test statistic and known variance (w.l.o.g. variance of
the test statistic is 1).
This situation corresponds to a classical $z$-test for
a difference in population means.
The null hypothesis is no population mean difference, i.e.
$\mathcal{H}_0:\delta \leq 0$.
An alternative effect size of $\delta = 0.4$ with
point prior distribution is assumed. 
Across all variants in this scenario, the one-sided maximal 
type one error rate is restricted to $\alpha=0.025$ 
and the power at the point alternative of $\delta=0.4$ must
be at least $0.8$.

```{r}
# data distribution and hypotheses
datadist   <- Normal(two_armed = TRUE)
H_0        <- PointMassPrior(.0, 1)
prior      <- PointMassPrior(.4, 1)

# define constraints
alpha      <- 0.025
min_power  <- 0.8
toer_cnstr <- Power(datadist, H_0)   <= alpha
pow_cnstr  <- Power(datadist, prior) >= min_power
```



## Variant I-1: Minimizing Expected Sample Size under Point Prior {#variantI_1}

### Objective

Firstly, expected sample size under the alternative (point prior) 
is minimized, i.e.,
$\boldsymbol{E}\big[n(\mathcal{D})\big]$.

```{r}
ess <- ExpectedSampleSize(datadist, prior)
```


### Constraints

No additional constraints besides type one error rate and power 
are considered in this variant.


### Initial Designs

For this example, the optimal one-stage, group-sequential, and generic
two-stage designs are computed.
The initial design for the one-stage case is determined heuristically
(cf. [Scenario III](#scenarioIII) where another initial design is applied
on the same situation for stability of initial values).
Both the group sequential and the generic two-stage designs are 
optimized starting from the corresponding group-sequential design as
computed by the `rpact` package.
```{r}
order <- 7L
# data frame of initial designs 
tbl_designs <- tibble(
    type    = c("one-stage", "group-sequential", "two-stage"),
    initial = list(
        OneStageDesign(200, 2.0),
        rpact_design(datadist, 0.4, 0.025, 0.8, TRUE, order),
        TwoStageDesign(rpact_design(datadist, 0.4, 0.025, 0.8, TRUE, order))) )
```

The order of integration is set to `r order`.


### Optimization 

```{r}
tbl_designs <- tbl_designs %>% 
    mutate(
       optimal = purrr::map(initial, ~minimize(
         
          ess,
          subject_to(
              toer_cnstr,
              pow_cnstr
          ),
          
          initial_design = ., 
          opts           = opts)) )
```



### Test Cases

To avoid improper solutions, it is first verified that the maximum
number of iterations was not exceeded in any of the three cases.
```{r}
tbl_designs %>% 
  transmute(
      type, 
      iterations = purrr::map_int(tbl_designs$optimal, 
                                  ~.$nloptr_return$iterations) ) %>%
  {print(.); .} %>% 
  {testthat::expect_true(all(.$iterations < opts$maxeval))}
```


Next, the type one error rate and power constraints are verified 
for all three designs by simulation:
```{r}
tbl_designs %>% 
  transmute(
      type, 
      toer  = purrr::map(tbl_designs$optimal, 
                         ~sim_pr_reject(.[[1]], .0, datadist)$prob), 
      power = purrr::map(tbl_designs$optimal, 
                         ~sim_pr_reject(.[[1]], .4, datadist)$prob) ) %>% 
  unnest(., cols = c(toer, power)) %>% 
  {print(.); .} %>% {
  testthat::expect_true(all(.$toer  <= alpha * (1 + tol)))
  testthat::expect_true(all(.$power >= min_power * (1 - tol))) }
```


The $n_2$ function of the optimal two-stage design is expected to be 
monotonously decreasing:
```{r}
expect_true(
    all(diff(
        # get optimal two-stage design n2 pivots
        tbl_designs %>% filter(type == "two-stage") %>%
           {.[["optimal"]][[1]]$design@n2_pivots} 
        ) < 0) )
```


Since the degrees of freedom of the three design classes are ordered as
'two-stage' > 'group-sequential' > 'one-stage',
the expected sample sizes (under the alternative) should be ordered 
in reverse ('two-stage' smallest).
Additionally, expected sample sizes under both null and alternative
are computed both via `evaluate()` and simulation-based.
```{r}
ess0 <- ExpectedSampleSize(datadist, H_0)

tbl_designs %>% 
    mutate(
        ess      = map_dbl(optimal,
                           ~evaluate(ess, .$design) ),
        ess_sim  = map_dbl(optimal,
                           ~sim_n(.$design, .4, datadist)$n ),
        ess0     = map_dbl(optimal,
                           ~evaluate(ess0, .$design) ),
        ess0_sim = map_dbl(optimal,
                           ~sim_n(.$design, .0, datadist)$n ) ) %>% 
    {print(.); .} %>% {
    # sim/evaluate same under alternative?
    testthat::expect_equal(.$ess, .$ess_sim, 
                           tolerance = tol_n,
                           scale = 1)
    # sim/evaluate same under null?
    testthat::expect_equal(.$ess0, .$ess0_sim, 
                           tolerance = tol_n,
                           scale = 1)
    # monotonicity with respect to degrees of freedom
    testthat::expect_true(all(diff(.$ess) < 0)) }
```

The expected sample size under the alternative must be lower or equal than
the expected sample size of the initial `rpact` group-sequential design that
is based on the inverse normal combination test.
```{r}
testthat::expect_lte(
  evaluate(ess, 
           tbl_designs %>%
             filter(type == "group-sequential") %>% 
             .$optimal %>% 
             .[[1]]  %>%
             .$design ),
    evaluate(ess, 
             tbl_designs %>% 
               filter(type == "group-sequential") %>% 
               .$initial %>% 
               .[[1]] ) )
```



## Variant I-2: Minimizing Expected Sample Size under Null Hypothesis {#variantI_2}

### Objective

Expected sample size under the null hypothesis prior is minimized, 
i.e., `ess0`.


### Constraints

The constraints remain unchanged from the base case.


### Initial Design

Since optimization under the null favours an entirely different 
(monotonically increasing) sample size function,
and thus also a different shape of the $c_2$ function,
the `rpact` initial design is a suboptimal starting point.
Instead, we start with a constant $c_2$ function by heuristically
setting it to $2$ on the continuation area.
Also, optimizing under the null favours extremely conservative 
boundaries for early efficacy stopping and we thus impose as fairly
liberal upper bound of $3$ for early efficacy stopping.

```{r}
init_design_h0 <- tbl_designs %>% 
    filter(type == "two-stage") %>% 
    .$initial %>% 
    .[[1]]
init_design_h0@c2_pivots <- rep(2, order)

ub_design <- TwoStageDesign(
    3 * init_design_h0@n1,
    2,
    3,
    rep(300, order),
    rep(3.0, order)
)
```

### Optimization 

The optimal two-stage design is computed. 

```{r}
opt_h0 <- minimize(
  
    ess0,
    
    subject_to(
        toer_cnstr,
        pow_cnstr
    ),
    
    initial_design        = init_design_h0,
    upper_boundary_design = ub_design,
    opts = opts )
```



### Test Cases

Make sure that the optimization algorithm converged within the set
maximum number of iterations:
```{r}
opt_h0$nloptr_return$iterations %>% 
    {print(.); .} %>% 
    {testthat::expect_true(. < opts$maxeval)}
```

The $n_2$ function of the optimal two-stage design is expected to be 
monotonously increasing.
```{r}
expect_true(
    all(diff(opt_h0$design@n2_pivots) > 0) )
```

Next, the type one error rate and power constraints are tested.
```{r}
tbl_performance <- tibble(
    delta = c(.0, .4) ) %>% 
    mutate(
        power     = map(
            delta, 
            ~evaluate(
                Power(datadist, PointMassPrior(., 1)), 
                opt_h0$design) ),
        power_sim = map(
            delta, 
            ~sim_pr_reject(opt_h0$design, ., datadist)$prob),
        ess       = map(
            delta, 
            ~evaluate(ExpectedSampleSize(
                    datadist, 
                    PointMassPrior(., 1) ), 
                opt_h0$design) ),
        ess_sim   = map(
            delta, 
            ~sim_n(opt_h0$design, . ,datadist)$n ) ) %>% 
    unnest(., cols = c(power, power_sim, ess, ess_sim))

print(tbl_performance)

testthat::expect_lte(
    tbl_performance %>% filter(delta == 0) %>% .$power_sim,
    alpha * (1 + tol) )

testthat::expect_gte(
    tbl_performance %>% filter(delta == 0.4) %>% .$power_sim,
    min_power * (1 - tol) )

# make sure that evaluate() leads to same results
testthat::expect_equal(
    tbl_performance$power, tbl_performance$power_sim, 
    tol   = tol,
    scale = 1 )

testthat::expect_equal(
    tbl_performance$ess, tbl_performance$ess_sim, 
    tol   = tol_n,
    scale = 1 )
```

The expected sample size under the null must be lower or equal than
the expected sample size of the initial `rpact` group-sequential design.
```{r}
testthat::expect_gte(
    evaluate(ess0, 
             tbl_designs %>% 
                filter(type == "two-stage") %>% 
                .$initial %>% 
                .[[1]] ),
    evaluate(ess0, opt_h0$design) )
```







## Variant I-3: Conditional Power Constraint {#variantI_3}


### Objective

Same as in [I-1](#variantI_1), i.e., expected sample size under the 
alternative point prior is minimized.


### Constraints

Besides the previous global type one error rate and power constraints,
an additional constraint on *conditional* power is imposed.
```{r}
cp       <- ConditionalPower(datadist, prior)
cp_cnstr <- cp >= .7
```


### Initial Design

The same initial (generic two-stage) design as in [I-1](#variantI_1) is used.


### Optimization 

```{r}
opt_cp <- minimize(
      
    ess,
    subject_to(
        toer_cnstr,
        pow_cnstr,
        cp_cnstr # new constraint
    ),

    initial_design = tbl_designs %>% 
        filter(type == "two-stage") %>% 
        .$initial %>% 
        .[[1]],
    opts = opts )
```



### Test Cases

Check if the optimization algorithm converged.

```{r}
opt_cp$nloptr_return$iterations %>% 
    {print(.); .} %>% 
    {testthat::expect_true(. < opts$maxeval)}
```

Check constraints.

```{r}
tbl_performance <- tibble(
    delta = c(.0, .4) ) %>% 
    mutate(
        power     = map(
            delta, 
            ~evaluate(
                Power(datadist, PointMassPrior(., 1)), 
                opt_cp$design) ),
        power_sim = map(
            delta, 
            ~sim_pr_reject(opt_cp$design, ., datadist)$prob),
        ess       = map(
            delta, 
            ~evaluate(ExpectedSampleSize(
                    datadist, 
                    PointMassPrior(., 1) ), 
                opt_cp$design) ),
        ess_sim   = map(
            delta, 
            ~sim_n(opt_cp$design, . ,datadist)$n ) ) %>% 
    unnest(., cols = c(power, power_sim, ess, ess_sim))

print(tbl_performance)

testthat::expect_lte(
    tbl_performance %>% filter(delta == 0) %>% .$power_sim,
    alpha * (1 + tol) )

testthat::expect_gte(
    tbl_performance %>% filter(delta == 0.4) %>% .$power_sim,
    min_power * (1 - tol) )

# make sure that evaluate() leads to same results
testthat::expect_equal(
    tbl_performance$power, tbl_performance$power_sim, 
    tol   = tol,
    scale = 1 )

testthat::expect_equal(
    tbl_performance$ess, tbl_performance$ess_sim, 
    tol   = tol_n,
    scale = 1 )
```

The conditional power constraint is evaluated and tested on a 
grid over the continuation region (both simulated an via numerical
integration).

```{r}
tibble(
    x1     = seq(opt_cp$design@c1f, opt_cp$design@c1e, length.out = 25),
    cp     = map_dbl(x1, ~evaluate(cp, opt_cp$design, .)),
    cp_sim = map_dbl(x1, function(x1) {
        x2  <- simulate(datadist, 10^6, n2(opt_cp$design, x1), .4, 42)
        rej <- ifelse(x2 > c2(opt_cp$design, x1), 1, 0)
        return(mean(rej))
    }) ) %>% 
  {print(.); .} %>% {
      testthat::expect_true(all(.$cp     >= 0.7 * (1 - tol)))
      testthat::expect_true(all(.$cp_sim >= 0.7 * (1 - tol))) 
      testthat::expect_true(all(abs(.$cp - .$cp_sim) <= tol)) }
```

Finally, the expected sample size under the alternative prior should 
be larger than in the case without the constraint [I-1](#variantI_1).

```{r}
testthat::expect_gte(
    evaluate(ess, opt_cp$design),
    evaluate(
        ess, 
        tbl_designs %>% 
            filter(type == "two-stage") %>% 
            .$optimal %>% 
            .[[1]] %>% 
            .$design ) )
```





## Plot Two-Stage Designs

The following figure shows the three optimal two-stage designs side by 
side.
The effect of the conditional power constraint (CP not below 0.7) is
clearly visible and the very different characteristics between
optimizing under the null or the alternative are clearly visible.

```{r, echo=FALSE}
x1 <- seq(0, 3.5, by = .01)

tibble(
    type  = c(
        "ESS under alternative", 
        "ESS under null", 
        "ESS under alternative + CP constraint" ), 
    design = list(
        tbl_designs %>% 
            filter(type == "two-stage") %>% 
            .$optimal %>% 
            .[[1]] %>% 
            .$design, 
        opt_h0$design, 
        opt_cp$design ) ) %>% 
    group_by(type) %>% 
    do(
        x1 = x1,
        n  = adoptr::n(.$design[[1]], x1),
        c2 = c2(.$design[[1]], x1),
        CP = evaluate(cp, .$design[[1]], x1) ) %>% 
    unnest(., cols = c(x1, n, c2, CP)) %>% 
    mutate(
        section = ifelse(
            is.finite(c2), 
            "continuation", 
            ifelse(c2 == -Inf, "efficacy", "futility") ) ) %>% 
    gather(variable, value, n, c2, CP) %>% 
    ggplot(aes(x1, value, color = type)) +
        geom_line(aes(group = interaction(section, type))) + 
        facet_wrap(~variable, scales = "free_y") +
        labs(y = "", x = expression(x[1])) +
        scale_color_discrete("") +
        theme_bw() +
        theme(
            panel.grid      = element_blank(),
            legend.position = "bottom" )
```

